# Week 1: ML Foundations for AI Red Teamers
**Transforming Web/Cloud Pentesters into AI Security Specialists**

---

## Week 1 Learning Objectives

By the end of Week 1, you will be able to:

1. **Identify AI/ML attack surfaces** in production environments (analogous to network/service mapping in traditional pentesting)
2. **Build and query ML models** to establish baseline behavior for adversarial testing (like establishing normal traffic patterns for fuzzing)
3. **Map OWASP ML Top 10 vulnerabilities** to familiar web/cloud attack patterns (SQL injection â†’ membership inference)
4. **Execute basic model inference** to extract behavior patterns (similar to fingerprinting web services)
5. **Document threat models** specific to ML systems (extending traditional infrastructure threat modeling)

---

## How This Maps to AI Red Team Work

Every activity in Week 1 directly prepares you for real AI red team engagements:

| **Week 1 Activity** | **Red Team Skill** | **Real-World Scenario** |
|---------------------|-------------------|-------------------------|
| Build MNIST classifier | Understand model architecture before attacking | Client ML model assessment - need to know what you're attacking |
| OWASP ML Top 10 mapping | Vulnerability classification in AI systems | AI pentest scope definition and threat surface identification |
| Query model predictions | Extract model behavior patterns | Membership inference attacks, model fingerprinting |
| Text generator | Understanding generative model mechanics | LLM security assessments, prompt injection vulnerability discovery |
| Attack surface mapping | Identify ML pipeline components | Comprehensive AI security audit starting with threat modeling |

---

## Detailed Learning Path

### Objective 1: Build & Query ML Models
**Why This Matters for Red Team Work:**
- You need to understand what "normal" looks like before you can identify anomalies or inject adversarial samples
- Model querying is the first step in reconnaissance for AI systems (similar to port scanning)
- Production models are often black boxes - learning to interact with them programmatically is essential

**What You'll Build:**
- MNIST CNN classifier (image classification model)
- Simple text generator (generative model baseline)
- Model serving endpoint (understanding deployment attack surface)

**Red Team Application:**
```
Real Scenario: You're hired to assess a client's ML-powered fraud detection system.
Week 1 Skills Applied:
1. Query model predictions to understand decision boundaries
2. Identify model inputs/outputs (attack vectors)
3. Document model behavior for exploit development
```

---

### Objective 2: Map Pentest Methodology to AI Security
**Why This Matters for Red Team Work:**
- AI pentesting follows similar phases to traditional pentesting (recon, scanning, exploitation, persistence)
- Familiar methodology = faster adaptation to AI security assessments
- Industry-standard frameworks (MITRE ATLAS, OWASP) use similar structure to traditional security

**What You'll Learn:**
- Traditional pentest lifecycle: Recon â†’ Scanning â†’ Enumeration â†’ Exploitation â†’ Reporting
- AI pentest lifecycle: Model Recon â†’ Adversarial Query â†’ Attack Implementation â†’ Impact Assessment â†’ Reporting
- Direct parallels: SQL injection â†’ Membership inference, XSS â†’ Prompt injection, CSRF â†’ Model stealing

**Red Team Application:**
```
Phase Mapping:
Traditional Pentest          AI Security Equivalent
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Port scanning            â†’    Model fingerprinting
Service enumeration      â†’    Architecture extraction
Vulnerability scanning   â†’    Adversarial testing
Exploitation             â†’    Adversarial sample injection
```

---

### Objective 3: OWASP ML Top 10 Vulnerability Mapping
**Why This Matters for Red Team Work:**
- OWASP ML Top 10 is the industry standard for AI vulnerability classification (like OWASP Top 10 for web)
- Understanding these vulnerabilities guides your attack methodology
- Every major AI security consulting firm uses this framework for scoping and reporting

**What You'll Master:**
- Map each OWASP ML Top 10 vulnerability to familiar attack patterns
- Create attack scenarios for each vulnerability class
- Understand business impact (CVSS-like scoring for AI vulnerabilities)

**Red Team Application:**
```
Vulnerability Mapping:
Web Security          AI Security                Business Impact
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SQL Injection    â†’    Input Manipulation (M01)   Data breach
Broken Auth     â†’    Supply Chain Attack (M05)   Model compromise
XSS             â†’    Prompt Injection (M10)      System control
Insecure API    â†’    ML Model Endpoint (M07)     Inference attacks
```

---

### Objective 4: Build Practical Exploitation Targets
**Why This Matters for Red Team Work:**
- You need models to practice attacks on (can't test exploits against client production systems)
- Understanding how models work internally helps you craft better adversarial samples
- Building models teaches you where vulnerabilities get introduced (during training, deployment, etc.)

**What You'll Create:**
- Target model for subsequent weeks' attacks (MNIST classifier)
- Model deployment setup (FastAPI server - similar to real production deployments)
- Baseline performance metrics (to measure attack effectiveness)

**Red Team Application:**
```
Exploitation Chain (Weeks 3-4 Preview):
Week 1: Build model â†’ Normal accuracy: 98%
Week 3: Evasion attack â†’ Adversarial accuracy: <5%
Week 4: Poison attack â†’ Compromise model from training data
Week 7: Defense evaluation â†’ Measure robustness improvements

This mimics real AI pentest workflow:
1. Baseline establishment
2. Vulnerability identification
3. Proof-of-concept exploits
4. Risk assessment
5. Remediation recommendations
```

---

### Objective 5: Establish Testing Infrastructure
**Why This Matters for Red Team Work:**
- Professional pentesting requires organized tools, data, and documentation
- AI security testing needs specific tooling (PyTorch, Jupyter, adversarial libraries)
- Proper environment setup prevents "works on my machine" issues during client engagements

**What You'll Set Up:**
- Development environment with all AI security tools
- Model storage and versioning
- Attack harness structure (for organizing exploits)
- Lab notebook for tracking findings

**Red Team Application:**
```
Professional Setup = Credibility
Proper tools and organization is what separates hobbyists from 
professional consultants. Week 1 foundation enables:

âœ“ Consistent testing methodology across engagements
âœ“ Reproducible results for client reports
âœ“ Scalable attack tooling (reuse across assessments)
âœ“ Professional documentation standards
```

---

## ðŸŽ“ Success Criteria

You'll know you've mastered Week 1 when you can:

1. **Load an ML model and execute inference** (basic AI recon skill)
2. **Explain how at least 5 OWASP ML vulnerabilities map to web security** (translation skill for pentesters)
3. **Build a working ML model from scratch** (understanding architecture for attack development)
4. **Query model predictions programmatically** (automation for large-scale testing)
5. **Document ML threat model** using familiar pentesting methodology

---

## Real-World Application: Week 1 â†’ Future Work

### How Week 1 Enables Week 3 (Evasion Attacks)
```
Week 1 Foundation:
â”œâ”€ Understanding model architecture â†’ Know where to inject adversarial perturbations
â”œâ”€ Model querying skills â†’ Automate large-scale attack testing
â””â”€ Baseline performance â†’ Measure attack success rate

Week 3 Application:
â”œâ”€ FGSM attack â†’ Manipulate inputs based on architecture knowledge
â”œâ”€ Automated evasion â†’ Use Week 1 querying for batch processing
â””â”€ Impact assessment â†’ Compare Week 1 baseline vs Week 3 adversarial accuracy
```

### How Week 1 Enables Week 5 (LLM Security)
```
Week 1 Foundation:
â”œâ”€ Text generation understanding â†’ Know how LLMs generate outputs
â”œâ”€ Model inference skills â†’ Craft prompt injections
â””â”€ OWASP mapping â†’ Connect prompt injection to XSS patterns

Week 5 Application:
â”œâ”€ Jailbreak crafting â†’ Use LLM architecture knowledge
â”œâ”€ Systematic testing â†’ Apply Week 1 methodology to LLM endpoints
â””â”€ Vulnerability classification â†’ Categorize findings using OWASP framework
```

### How Week 1 Enables Professional Work
```
Day 1 on AI Pentest Engagement:

Morning:
â”œâ”€ Client meeting: "Assess our fraud detection ML model"
â”œâ”€ Apply Week 1 skills: Query model API, extract behavior patterns
â””â”€ Map threat surfaces using OWASP ML Top 10

Afternoon:
â”œâ”€ Develop testing plan based on Week 1 methodology
â”œâ”€ Set up testing environment (like Week 1 setup)
â””â”€ Begin baseline assessment (Week 1 inference skills)

Week 1 skills used: Model querying, threat modeling, OWASP framework
```

---

## Required Materials & Resources

### Textbooks
- **GÃ©ron Ch. 1-4**: ML fundamentals (data, training, evaluation)
- **Sotiropoulos Ch. 1**: Introduction to AI security and attack taxonomy

### Tools & Libraries
- PyTorch (model building)
- Matplotlib (visualization of results)
- Jupyter Notebooks (interactive development)
- FastAPI (model serving - understanding deployment)

### External References (for context, not copying)
- GÃ©ron GitHub: https://github.com/ageron/handson-ml3 (reference implementations)
- OWASP ML Top 10: https://owasp.org/www-project-machine-learning-security-top-10/
- MITRE ATLAS: https://atlas.mitre.org/ (attack framework)

---

## Week 1 Deliverables Checklist

Each deliverable directly supports AI red team work:

- [ ] **`mnist_classifier.ipynb`** - Working model you'll attack in Week 3
- [ ] **`text_generator.ipynb`** - Understanding generative models for Week 5 LLM work
- [ ] **`ml_attack_surfaces.md`** - Threat model template for client engagements
- [ ] **`owasp_ml_mapping.md`** - Vulnerability reference guide for scoping
- [ ] **Lab notebook entries** - Documenting baseline metrics for attack impact measurement
- [ ] **Working model API** (FastAPI) - Understanding production deployment attack surface

---

## The Bottom Line

**Week 1 isn't just "learning ML basics" - it's building the foundation for AI red team work.**

Every concept, every line of code, every exercise is deliberately designed to:
- Build attack targets for future weeks
- Establish methodology for professional engagements
- Create reference materials you'll use in real work
- Develop the mindset shift from "how ML works" to "how to attack ML"

By Week 8, you'll look back at Week 1 and realize:
- "I built the models I learned to exploit"
- "The OWASP mapping helped me scope my first AI pentest"
- "The threat model template I created is now my go-to for client work"
- "Understanding model architecture gave me the insight to craft novel attacks"

**This isn't a course about ML - it's a transition from web/cloud pentester to AI red team specialist.**
