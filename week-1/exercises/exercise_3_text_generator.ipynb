{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Week 1 - Exercise 3: Simple Text Generator\n",
    "\n",
    "Objective: Understand generative models (prepares for LLM attacks in Week 5)\n",
    "\n",
    "INSTRUCTIONS:\n",
    "This script is ~85% complete. Your task is to fill in the TODO sections.\n",
    "This exercise teaches the fundamentals of how LLMs generate text.\n",
    "\n",
    "Red Team Context: LLMs work similarly - understanding this foundation is crucial \n",
    "for prompt injection and jailbreak attacks in Week 5.\n",
    "\n",
    "You'll build a simple RNN that generates text character-by-character.\n",
    "This teaches you how generative models work, which is essential for attacking LLMs.\n",
    "\"\"\"\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # STEP 1: PREPARE TRAINING DATA\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "print(\"Preparing training data...\")\n",
    "\n",
    "# Simple text corpus (Shakespeare-inspired)\n",
    "text = \"\"\"\n",
    "To be or not to be that is the question\n",
    "Whether tis nobler in the mind to suffer\n",
    "The slings and arrows of outrageous fortune\n",
    "Or to take arms against a sea of troubles\n",
    "And by opposing end them\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "# Clean and prepare text\n",
    "text = text.lower().replace('\\n', ' ')\n",
    "text = ' '.join(text.split())  # Remove extra whitespace\n",
    "\n",
    "print(f\"Training text length: {len(text)} characters\")\n",
    "print(f\"First 100 characters: {text[:100]}\")\n",
    "\n",
    "# Create character mappings\n",
    "chars = sorted(set(text))\n",
    "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "vocab_size = len(chars)\n",
    "print(f\"\\nVocabulary size: {vocab_size} unique characters\")\n",
    "print(f\"Characters: {chars}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: CREATE TRAINING SEQUENCES\n",
    "# ============================================================================\n",
    "print(\"\\nCreating training sequences...\")\n",
    "\n",
    "def create_sequences(text, seq_length=50):\n",
    "    \"\"\"\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "    Create sequences of characters for training.\n",
    "    Input: \"hello world\"\n",
    "    Output: \n",
    "      X: [\"hello world\", \"ello world \", ...]\n",
    "      y: [next_char for each sequence]\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    # TODO: Create training sequences\n",
    "    # HINT: Loop through text, extract sequences of length seq_length\n",
    "    # For each sequence, the target is the next character\n",
    "    # Convert characters to indices using char_to_idx dictionary\n",
    "    \n",
    "    for i in range(len(text) - seq_length):\n",
    "        # TODO: Extract sequence and next character\n",
    "        seq = None  # Extract seq_length characters starting at position i\n",
    "        next_char = None  # Extract the character immediately after the sequence\n",
    "        \n",
    "        # TODO: Convert to indices and append to X and y\n",
    "        X.append(None)  # Convert seq to list of indices\n",
    "        y.append(None)  # Convert next_char to index\n",
    "    \n",
    "    return torch.tensor(X), torch.tensor(y)\n",
    "\n",
    "seq_length = 30\n",
    "X, y = create_sequences(text, seq_length)\n",
    "\n",
    "print(f\"Created {len(X)} training sequences\")\n",
    "print(f\"Sequence length: {seq_length}\")\n",
    "print(f\"Example sequence: {''.join([idx_to_char[i] for i in X[0]])}\")\n",
    "print(f\"Next character: {idx_to_char[y[0].item()]}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: DEFINE RNN MODEL\n",
    "# ============================================================================\n",
    "print(\"\\nDefining RNN model...\")\n",
    "\n",
    "class CharRNN(nn.Module):\n",
    "    \"\"\"\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "    Simple character-level RNN for text generation.\n",
    "    \n",
    "    Architecture:\n",
    "    - Embedding layer: convert char indices to vectors\n",
    "    - LSTM layer: process sequences\n",
    "    - Linear layer: predict next character\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=256, num_layers=2):\n",
    "        super(CharRNN, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Embedding: convert char indices to dense vectors\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # LSTM: process sequences\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, \n",
    "                           batch_first=True, dropout=0.2 if num_layers > 1 else 0)\n",
    "        \n",
    "        # Output layer: predict next character\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        # x: (batch, seq_length)\n",
    "        # TODO: Apply embedding layer\n",
    "        # HINT: self.embedding(x) converts character indices to dense vectors\n",
    "        x = None\n",
    "        \n",
    "        # TODO: Apply LSTM layer\n",
    "        # HINT: self.lstm(x, hidden) processes the sequence\n",
    "        lstm_out, hidden = None, None\n",
    "        \n",
    "        # TODO: Get final output and apply fully connected layer\n",
    "        # HINT: Use lstm_out[:, -1, :] to get last timestep, then apply self.fc\n",
    "        out = None\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"Initialize hidden state.\"\"\"\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "        weight = next(self.parameters())\n",
    "        h0 = weight.new_zeros(self.num_layers, batch_size, self.hidden_dim)\n",
    "        c0 = weight.new_zeros(self.num_layers, batch_size, self.hidden_dim)\n",
    "        return (h0, c0)\n",
    "\n",
    "# Initialize model\n",
    "model = CharRNN(vocab_size)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # STEP 4: SET UP TRAINING\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "print(\"\\nSetting up training...\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training configuration\n",
    "num_epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "print(f\"Training for {num_epochs} epochs...\")\n",
    "\n",
    "# Check if sequences were created properly\n",
    "if len(X) == 0:\n",
    "    print(\"\\n\u274c ERROR: No training sequences created!\")\n",
    "    print(\"   Please complete the TODO in create_sequences() function.\")\n",
    "    exit()\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # STEP 5: TRAINING LOOP\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "print(\"\\nTraining model...\")\n",
    "\n",
    "losses = []\n",
    "model.train()\n",
    "\n",
    "# Add try/except to catch TODO-related errors\n",
    "for epoch in range(num_epochs):\n",
    "    try:\n",
    "        # Create random batches\n",
    "        indices = torch.randperm(len(X))\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for i in range(0, len(X), batch_size):\n",
    "            batch_indices = indices[i:i + batch_size]\n",
    "            batch_X = X[batch_indices]\n",
    "            batch_y = y[batch_indices]\n",
    "            \n",
    "            # TODO: Forward pass\n",
    "            # 1. Zero gradients: optimizer.zero_grad()\n",
    "            # 2. Initialize hidden state: model.init_hidden(len(batch_X))\n",
    "            # 3. Get model output: model(batch_X, hidden)\n",
    "            # 4. Calculate loss: criterion(output, batch_y)\n",
    "            \n",
    "            # TODO: Backward pass\n",
    "            # 1. Compute gradients: loss.backward()\n",
    "            # 2. Clip gradients: torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "            # 3. Update weights: optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / (len(X) // batch_size)\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        # Print progress every 20 epochs\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "    except (AttributeError, RuntimeError, TypeError) as e:\n",
    "        print(f\"\\n\u274c ERROR during training: {e}\")\n",
    "        print(\"\\nCheck your TODO implementations:\")\n",
    "        print(\"  - Did you implement create_sequences()?\")\n",
    "        print(\"  - Did you implement the model forward pass?\")\n",
    "        print(\"  - Did you implement the training loop TODOs?\")\n",
    "        exit()\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # STEP 6: VISUALIZE TRAINING PROGRESS\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True)\n",
    "plt.savefig('text_generator_training.png', dpi=150)\n",
    "print(\"\\nSaved: text_generator_training.png\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # STEP 7: GENERATE TEXT\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "print(\"\\nGenerating text...\")\n",
    "\n",
    "def generate_text(model, start_string, length=100, temperature=1.0):\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\"\n",
    "    Generate text starting from a given string.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RNN model\n",
    "        start_string: Initial text to start generation\n",
    "        length: Number of characters to generate\n",
    "        temperature: Controls randomness (higher = more random)\n",
    "    \"\"\"\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "    model.eval()\n",
    "    \n",
    "    # Convert start string to indices\n",
    "    input_seq = torch.tensor([[char_to_idx[ch] for ch in start_string]])\n",
    "    \n",
    "    generated = list(start_string)\n",
    "    hidden = model.init_hidden(1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Process start string\n",
    "        for i in range(len(start_string) - 1):\n",
    "            output, hidden = model(input_seq[:, i:i+1], hidden)\n",
    "        \n",
    "        # Generate new characters\n",
    "        for _ in range(length):\n",
    "            # TODO: Get next character prediction\n",
    "            # 1. Get model output for last character: model(input_seq[:, -1:], hidden)\n",
    "            \n",
    "            # TODO: Apply temperature and sample\n",
    "            # 1. Divide output by temperature\n",
    "            # 2. Apply softmax to get probabilities\n",
    "            # 3. Sample from probability distribution using torch.multinomial()\n",
    "            \n",
    "            # TODO: Convert to character and add to sequence\n",
    "            # 1. Convert index to character: idx_to_char[next_char_idx]\n",
    "            # 2. Add to generated list\n",
    "            # 3. Append to input_seq for next iteration\n",
    "            \n",
    "            generated.append(None)  # Add generated character\n",
    "            input_seq = None  # Update input sequence\n",
    "    \n",
    "    return ''.join(generated)\n",
    "\n",
    "# Generate 10 samples\n",
    "start_string = \"to be or not\"\n",
    "num_samples = 10\n",
    "\n",
    "print(f\"\\nGenerating {num_samples} samples from '{start_string}':\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i in range(num_samples):\n",
    "    generated = generate_text(model, start_string, length=80, temperature=0.8)\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"  {generated}\")\n",
    "    print()\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # STEP 8: ANALYZE MODEL BEHAVIOR\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "print(\"\\nAnalyzing model behavior...\")\n",
    "\n",
    "# Test different temperatures\n",
    "print(\"\\nEffect of temperature on generation:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "temperatures = [0.5, 1.0, 2.0]\n",
    "for temp in temperatures:\n",
    "    generated = generate_text(model, \"to be\", length=50, temperature=temp)\n",
    "    print(f\"\\nTemperature {temp}:\")\n",
    "    print(f\"  {generated}\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # STEP 9: SAVE MODEL\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "model_path = 'char_rnn_model.pt'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'char_to_idx': char_to_idx,\n",
    "    'idx_to_char': idx_to_char,\n",
    "    'vocab_size': vocab_size,\n",
    "    'model_config': {\n",
    "        'hidden_dim': 256,\n",
    "        'num_layers': 2\n",
    "    }\n",
    "}, model_path)\n",
    "print(f\"\\n\u2713 Model saved to {model_path}\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# DOCUMENTATION\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Exercise 3 Complete!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nWhat you accomplished:\")\n",
    "print(\"1. \u2713 Built a character-level RNN for text generation\")\n",
    "print(\"2. \u2713 Trained the model on Shakespeare text\")\n",
    "print(\"3. \u2713 Generated 10 text samples\")\n",
    "print(\"4. \u2713 Analyzed effect of temperature on generation\")\n",
    "print(\"5. \u2713 Saved model for future use\")\n",
    "print(\"\\nKey Concepts Learned:\")\n",
    "print(\"  - Character-level modeling (input: character, output: next character)\")\n",
    "print(\"  - LSTM for sequence modeling\")\n",
    "print(\"  - Text generation via sampling from probability distribution\")\n",
    "print(\"  - Temperature controls randomness in generation\")\n",
    "print(\"\\nRed Team Context:\")\n",
    "print(\"  LLMs work similarly to this RNN:\")\n",
    "print(\"  - They predict the next token (word/character) given context\")\n",
    "print(\"  - Generation involves sampling from probability distributions\")\n",
    "print(\"  - Understanding this helps you craft effective prompt injections\")\n",
    "print(\"\\nConnection to Week 5 (LLM Attacks):\")\n",
    "print(\"  - Prompt injection: manipulating the input context\")\n",
    "print(\"  - Jailbreaks: exploiting generation patterns\")\n",
    "print(\"  - Token manipulation: understanding how models process input\")\n",
    "print(\"\\nYour simple RNN foundation \u2192 Advanced LLM attacks!\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}