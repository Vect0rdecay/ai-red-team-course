{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Week 1 - Exercise 1: MNIST Classifier\n",
    "\n",
    "Objective: Build and train a CNN to classify handwritten digits.\n",
    "This model will become your evasion attack target in Week 3.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "This script is ~85% complete. Your task is to fill in the TODO sections marked with:\n",
    "  # TODO: Your implementation here\n",
    "  \n",
    "Each TODO includes hints. Read the hints carefully before implementing.\n",
    "After completing all TODOs, run the script to train your model.\n",
    "\n",
    "Red Team Context: You need attack targets to practice on. This model with 98% \n",
    "accuracy will be reduced to <5% using adversarial samples in Week 3.\n",
    "\"\"\"\n"
   ],
   "id": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # STEP 1: IMPORT REQUIRED LIBRARIES\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # STEP 2: SET DEVICE AND PATHS\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create directory for saving models\n",
    "model_dir = Path(__file__).parent.parent.parent / \"models\"\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # STEP 3: LOAD AND PREPROCESS MNIST DATASET\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# TODO: Define transforms for converting PIL images to PyTorch tensors\n",
    "# HINT: Use transforms.Compose with ToTensor() and Normalize()\n",
    "# MNIST normalization values: mean=(0.1307,), std=(0.3081,)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # TODO: Add ToTensor() transform to convert PIL images to tensors\n",
    "    # TODO: Add Normalize() transform with MNIST mean and std values\n",
    "])\n",
    "\n",
    "print(\"\\nDownloading MNIST dataset...\")\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Visualize sample images\n",
    "print(\"\\nVisualizing sample images...\")\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "for i in range(8):\n",
    "    img, label = train_dataset[i]\n",
    "    axes[i // 4, i % 4].imshow(img.squeeze(), cmap='gray')\n",
    "    axes[i // 4, i % 4].set_title(f\"Label: {label}\")\n",
    "    axes[i // 4, i % 4].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('mnist_samples.png')\n",
    "print(\"Sample images saved to mnist_samples.png\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # STEP 4: DEFINE CNN ARCHITECTURE\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "class MNIST_CNN(nn.Module):\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\"\n",
    "    Simple CNN for MNIST classification.\n",
    "    \n",
    "    Architecture:\n",
    "    - Conv1: 1 -> 32 channels\n",
    "    - Pool1: Max pooling 2x2\n",
    "    - Conv2: 32 -> 64 channels\n",
    "    - Pool2: Max pooling 2x2\n",
    "    - FC1: 64*5*5 -> 128\n",
    "    - FC2: 128 -> 10 (classes)\n",
    "    \"\"\"\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "    def __init__(self):\n",
    "        super(MNIST_CNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Pooling\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        # Activation\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Conv block 1: Apply conv1, ReLU, then pool\n",
    "        # TODO: Apply self.conv1, self.relu, then self.pool to x\n",
    "        x = None  # Replace with your implementation\n",
    "        \n",
    "        # Conv block 2: Apply conv2, ReLU, then pool\n",
    "        # TODO: Apply self.conv2, self.relu, then self.pool to x\n",
    "        x = None  # Replace with your implementation\n",
    "        \n",
    "        # Flatten: Reshape from (batch, channels, height, width) to (batch, features)\n",
    "        # TODO: Use .view() to flatten the tensor\n",
    "        x = None  # Replace with your implementation\n",
    "        \n",
    "        # Fully connected layers\n",
    "        # TODO: Apply fc1 with ReLU, then fc2\n",
    "        x = None  # Replace with your implementation\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = MNIST_CNN().to(device)\n",
    "print(f\"\\nModel created with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # STEP 5: DEFINE LOSS FUNCTION AND OPTIMIZER\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# TODO: Choose appropriate loss function for multi-class classification\n",
    "# HINT: Use nn.CrossEntropyLoss() for classification tasks\n",
    "\n",
    "criterion = None  # Replace with your implementation\n",
    "\n",
    "# TODO: Choose optimizer and set learning rate\n",
    "# HINT: Adam optimizer with lr=0.001 is a good starting point\n",
    "optimizer = None  # Replace with your implementation\n",
    "\n",
    "# Print confirmation\n",
    "if criterion is None or optimizer is None:\n",
    "    print(\"\u26a0 TODO: Implement loss function and optimizer before training!\")\n",
    "else:\n",
    "    print(f\"Loss function: {criterion}\")\n",
    "    print(f\"Optimizer: {optimizer}\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # STEP 6: TRAINING LOOP\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # TODO: Forward pass\n",
    "        # 1. Zero gradients: optimizer.zero_grad()\n",
    "        # 2. Get model outputs: outputs = model(images)\n",
    "        # 3. Calculate loss: loss = criterion(outputs, labels)\n",
    "        \n",
    "        # TODO: Backward pass\n",
    "        # 1. Compute gradients: loss.backward()\n",
    "        # 2. Update weights: optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Train for 5 epochs\n",
    "num_epochs = 5\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "# Check if TODOs are completed\n",
    "if criterion is None or optimizer is None:\n",
    "    print(\"\\n\u274c ERROR: Please complete the TODO sections before training!\")\n",
    "    print(\"   - Implement loss function (Step 5)\")\n",
    "    print(\"   - Implement optimizer (Step 5)\")\n",
    "    print(\"   - Implement forward pass in model (Step 4)\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    try:\n",
    "        loss, acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        train_losses.append(loss)\n",
    "        train_accuracies.append(acc)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {loss:.4f}, Acc: {acc:.2f}%\")\n",
    "    except (AttributeError, RuntimeError) as e:\n",
    "        print(f\"\\n\u274c ERROR during training: {e}\")\n",
    "        print(\"\\nCheck your TODO implementations:\")\n",
    "        print(\"  - Did you implement the model forward pass?\")\n",
    "        print(\"  - Did you implement the training loop TODOs?\")\n",
    "        exit()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: EVALUATE ON TEST SET\n",
    "# ============================================================================\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    \"\"\"Evaluate model on test set.\"\"\"\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # TODO: Implement evaluation logic\n",
    "    # HINT: Similar to training but without backward pass\n",
    "    # Use torch.no_grad() to disable gradient computation\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # TODO: Get model outputs and calculate loss\n",
    "            # (Similar to training but no optimizer steps)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    test_acc = 100.0 * correct / total\n",
    "    return test_loss, test_acc\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"\\nTest Results: Loss: {test_loss:.4f}, Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "if test_acc >= 95.0:\n",
    "    print(\"\u2713 SUCCESS: Achieved >95% test accuracy!\")\n",
    "else:\n",
    "    print(\"\u26a0 WARNING: Test accuracy below 95%\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # STEP 8: VISUALIZE TRAINING PROGRESS\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies)\n",
    "plt.axhline(y=95, color='r', linestyle='--', label='Target (95%)')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png', dpi=150)\n",
    "print(\"\\nTraining curves saved to training_curves.png\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # STEP 9: SAVE MODEL\n"
   ],
   "id": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "model_path = model_dir / \"mnist_cnn.pt\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"\\nModel saved to: {model_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Exercise 1 Complete!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nWhat you accomplished:\")\n",
    "print(\"1. Built a CNN for MNIST classification\")\n",
    "print(\"2. Achieved >95% accuracy (your baseline)\")\n",
    "print(\"3. Saved the model for Week 3 attacks\")\n",
    "print(f\"\\nBaseline accuracy: {test_acc:.2f}%\")\n",
    "print(\"This model will be attacked in Week 3 (evasion attacks)\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}