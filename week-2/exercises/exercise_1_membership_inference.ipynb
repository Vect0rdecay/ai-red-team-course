{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Week 2 - Exercise 1: Membership Inference Attack\n",
    "\n",
    "Objective: Implement a membership inference attack to detect training data leakage\n",
    "\n",
    "Red Team Context: This attack determines if specific samples were in the training data.\n",
    "This is a privacy violation (HIPAA/GDPR) - like SQL injection leaking database contents.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "This script is ~85% complete. Fill in the TODO sections marked with:\n",
    "  # TODO: Your implementation here\n",
    "  \n",
    "Each TODO includes hints. Read carefully before implementing.\n",
    "\n",
    "Expected Attack Success Rate: >60% (random guess = 50%)\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 1: SETUP AND IMPORTS\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Membership Inference Attack on MNIST Model\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 2: LOAD TRAINED MODEL FROM WEEK 1\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nLoading trained MNIST model from Week 1...\")\n",
    "\n",
    "# Define model architecture (same as Week 1)\n",
    "class MNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Load trained model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MNIST_CNN().to(device)\n",
    "\n",
    "model_path = Path(__file__).parent.parent.parent / \"models\" / \"mnist_cnn.pt\"\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(\"\u26a0 Error: Week 1 model not found!\")\n",
    "    print(\"   Please run Week 1, Exercise 1 first to train the model.\")\n",
    "    exit()\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "print(f\"\u2713 Model loaded successfully\")\n",
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 3: PREPARE DATA FOR MEMBERSHIP INFERENCE\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nPreparing data for membership inference...\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Split training data into member and non-member samples\n",
    "# In real attack, attacker doesn't know membership\n",
    "# Here we simulate it for testing\n",
    "train_size = len(train_dataset)\n",
    "member_size = train_size // 2\n",
    "\n",
    "# Split train into member and non-member\n",
    "member_data, non_member_data = random_split(\n",
    "    train_dataset, \n",
    "    [member_size, train_size - member_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "print(f\"Member samples (in training): {len(member_data)}\")\n",
    "print(f\"Non-member samples (not in training): {len(test_dataset)}\")\n",
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 4: FEATURE EXTRACTION FOR ATTACK MODEL\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nExtracting features for membership inference attack...\")\n",
    "\n",
    "def extract_features(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Extract features from target model predictions.\n",
    "    \n",
    "    Features used:\n",
    "    1. Predicted class confidence\n",
    "    2. Entropy of prediction distribution\n",
    "    3. Top-3 class confidences\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, _ in data_loader:\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # TODO: Get model predictions\n",
    "            # HINT: Call model(images) to get logits\n",
    "            \n",
    "            # TODO: Apply softmax to get probabilities\n",
    "            # HINT: Use torch.nn.functional.softmax(predictions, dim=1)\n",
    "            \n",
    "            # TODO: Extract features\n",
    "            # 1. Get predicted class confidence: probabilities.max(dim=1)[0]\n",
    "            # 2. Calculate entropy: -torch.sum(probabilities * torch.log(probabilities + 1e-9), dim=1)\n",
    "            # 3. Get top-3 confidences: probabilities.topk(3, dim=1)[0]\n",
    "            \n",
    "            # TODO: Combine features into single tensor\n",
    "            # HINT: Use torch.cat to concatenate features\n",
    "            sample_features = None  # Replace with your implementation\n",
    "            \n",
    "            features.append(sample_features.cpu())\n",
    "    \n",
    "    return torch.cat(features, dim=0)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "member_loader = DataLoader(member_data, batch_size=batch_size, shuffle=False)\n",
    "non_member_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Extract features\n",
    "print(\"Extracting features from member samples...\")\n",
    "member_features = extract_features(model, member_loader, device)\n",
    "\n",
    "print(\"Extracting features from non-member samples...\")\n",
    "non_member_features = extract_features(model, non_member_loader, device)\n",
    "\n",
    "if member_features is None or non_member_features is None:\n",
    "    print(\"\\n\u26a0 ERROR: Feature extraction not implemented!\")\n",
    "    print(\"   Please complete the TODO in extract_features()\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\nMember features shape: {member_features.shape}\")\n",
    "print(f\"Non-member features shape: {non_member_features.shape}\")\n",
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 5: BUILD TRAINING DATA FOR ATTACK MODEL\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nBuilding training data for attack model...\")\n",
    "\n",
    "# Create labels: 1 for member, 0 for non-member\n",
    "member_labels = torch.ones(len(member_features))\n",
    "non_member_labels = torch.zeros(len(non_member_features))\n",
    "\n",
    "# Combine features and labels\n",
    "X_attack = torch.cat([member_features, non_member_features], dim=0)\n",
    "y_attack = torch.cat([member_labels, non_member_labels], dim=0)\n",
    "\n",
    "# Shuffle data\n",
    "indices = torch.randperm(len(X_attack))\n",
    "X_attack = X_attack[indices]\n",
    "y_attack = y_attack[indices]\n",
    "\n",
    "print(f\"Attack training data shape: {X_attack.shape}\")\n",
    "print(f\"Member samples: {y_attack.sum().item()}\")\n",
    "print(f\"Non-member samples: {len(y_attack) - y_attack.sum().item()}\")\n",
    "\n",
    "# Split into train/val for attack model\n",
    "val_size = len(X_attack) // 5\n",
    "X_train_attack = X_attack[:-val_size]\n",
    "y_train_attack = y_attack[:-val_size]\n",
    "X_val_attack = X_attack[-val_size:]\n",
    "y_val_attack = y_attack[-val_size:]\n",
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 6: TRAIN ATTACK MODEL\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nTraining membership inference attack model...\")\n",
    "\n",
    "class AttackModel(nn.Module):\n",
    "    \"\"\"Attack model to predict membership from features.\"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super(AttackModel, self).__init__()\n",
    "        \n",
    "        # TODO: Define layers\n",
    "        # HINT: Use nn.Linear layers\n",
    "        # Suggested: input_dim -> 64 -> 32 -> 1\n",
    "        # Use ReLU activations between layers\n",
    "        self.fc1 = None  # Replace with your implementation\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = None  # Replace with your implementation\n",
    "        self.fc3 = None  # Replace with your implementation\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # TODO: Implement forward pass\n",
    "        # HINT: Apply fc1 -> relu -> fc2 -> relu -> fc3 -> sigmoid\n",
    "        x = None  # Replace with your implementation\n",
    "        return x\n",
    "\n",
    "# Initialize attack model\n",
    "input_dim = X_attack.shape[1]\n",
    "attack_model = AttackModel(input_dim)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(attack_model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Attack model input dimension: {input_dim}\")\n",
    "\n",
    "# TODO: Implement training loop\n",
    "# HINT: Similar to Week 1 training\n",
    "# 1. Forward pass\n",
    "# 2. Calculate loss\n",
    "# 3. Backward pass\n",
    "# 4. Update weights\n",
    "\n",
    "def train_attack_model(model, X, y, epochs=20):\n",
    "    \"\"\"Train the attack model.\"\"\"\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # TODO: Forward pass\n",
    "        # HINT: model(X), calculate loss with criterion\n",
    "        outputs = None\n",
    "        loss = None\n",
    "        \n",
    "        # TODO: Backward pass\n",
    "        # HINT: loss.backward(), optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"  Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "if X_train_attack is not None:\n",
    "    train_losses = train_attack_model(attack_model, X_train_attack, y_train_attack, epochs=20)\n",
    "    print(\"\u2713 Attack model training complete\")\n",
    "else:\n",
    "    print(\"\u26a0 TODO: Implement attack model training\")\n",
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 7: EVALUATE ATTACK PERFORMANCE\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nEvaluating attack performance...\")\n",
    "\n",
    "attack_model.eval()\n",
    "with torch.no_grad():\n",
    "    # TODO: Make predictions on validation set\n",
    "    # HINT: attack_model(X_val_attack)\n",
    "    val_predictions = None  # Replace with your implementation\n",
    "    \n",
    "    # TODO: Convert to binary predictions (>0.5 = member)\n",
    "    # HINT: val_predictions > 0.5\n",
    "    val_pred_binary = None  # Replace with your implementation\n",
    "\n",
    "if val_pred_binary is not None:\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_val_attack.numpy(), val_pred_binary.numpy())\n",
    "    \n",
    "    print(f\"\\nAttack Success Rate: {accuracy:.2%}\")\n",
    "    print(f\"(Random guess would be 50%)\")\n",
    "    \n",
    "    if accuracy > 0.55:\n",
    "        print(\"\u2713 Attack successful! Model leaks training data information.\")\n",
    "    else:\n",
    "        print(\"\u26a0 Attack not very successful. Model may be more secure.\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_val_attack.numpy(), val_pred_binary.numpy())\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Non-Member', 'Member'],\n",
    "                yticklabels=['Non-Member', 'Member'])\n",
    "    plt.title('Membership Inference Attack - Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('week-2/membership_inference_results.png', dpi=150)\n",
    "    print(\"\\nSaved: membership_inference_results.png\")\n",
    "else:\n",
    "    print(\"\u26a0 TODO: Implement attack evaluation\")\n",
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 8: ANALYSIS AND REPORTING\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Exercise 1 Complete!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nWhat you accomplished:\")\n",
    "print(\"1. \u2713 Extracted features from target model predictions\")\n",
    "print(\"2. \u2713 Trained membership inference attack model\")\n",
    "print(\"3. \u2713 Evaluated attack success rate\")\n",
    "print(\"4. \u2713 Generated confusion matrix visualization\")\n",
    "\n",
    "print(\"\\nRed Team Context:\")\n",
    "print(\"- Membership inference detects training data leakage\")\n",
    "print(\"- Attack success >60% indicates privacy vulnerability\")\n",
    "print(\"- This finding would appear in your AI pentest report\")\n",
    "\n",
    "print(\"\\nReal-World Impact:\")\n",
    "print(\"- HIPAA violation: Leaked patient data in training set\")\n",
    "print(\"- GDPR violation: Privacy regulation non-compliance\")\n",
    "print(\"- Competitive intelligence: Competitor can infer your training data\")\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}