{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Week 2 - Exercise 3: AI Vulnerability Reporting\n",
    "\n",
    "Objective: Generate professional AI security vulnerability reports\n",
    "\n",
    "Red Team Context: This is what you deliver to clients - professional pentest-style \n",
    "reports documenting AI model vulnerabilities with risk assessment and remediation.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "This script is ~85% complete. Fill in the TODO sections marked with:\n",
    "  # TODO: Your implementation here\n",
    "  \n",
    "Each TODO includes hints. Read carefully before implementing.\n",
    "\n",
    "Report sections include:\n",
    "- Executive summary\n",
    "- Technical details\n",
    "- Risk assessment\n",
    "- Proof of concept\n",
    "- Remediation recommendations\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 1: SETUP AND IMPORTS\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"AI Vulnerability Report Generator\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 2: LOAD ATTACK RESULTS\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nLoading attack results...\")\n",
    "\n",
    "# In real scenario, load results from exercises 1-2\n",
    "# For this exercise, we'll simulate attack results\n",
    "\n",
    "membership_attack_accuracy = 0.62  # From Exercise 1\n",
    "attack_success_rate = membership_attack_accuracy * 100\n",
    "\n",
    "print(f\"Membership inference attack success rate: {attack_success_rate:.1f}%\")\n",
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 3: CALCULATE RISK METRICS\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nCalculating risk metrics...\")\n",
    "\n",
    "def calculate_risk_score(attack_success_rate, potential_impact):\n",
    "    \"\"\"\n",
    "    Calculate risk score based on attack success and impact.\n",
    "    \n",
    "    Risk = (Attack Success - 50%) * Impact Factor\n",
    "    \n",
    "    Args:\n",
    "        attack_success_rate: Percentage of successful membership inference (0-100)\n",
    "        potential_impact: 1 (Low), 2 (Medium), 3 (High)\n",
    "    \n",
    "    Returns:\n",
    "        risk_score: Numerical risk score\n",
    "        severity: \"Low\", \"Medium\", \"High\", \"Critical\"\n",
    "    \"\"\"\n",
    "    # TODO: Calculate risk score\n",
    "    # HINT: risk = (attack_success_rate - 50) / 50 * potential_impact * 10\n",
    "    \n",
    "    # TODO: Determine severity based on score\n",
    "    # HINT: \n",
    "    #   score < 3: Low\n",
    "    #   3 <= score < 6: Medium\n",
    "    #   6 <= score < 9: High\n",
    "    #   score >= 9: Critical\n",
    "    \n",
    "    risk_score = None  # Replace with calculation\n",
    "    severity = None    # Replace with severity determination\n",
    "    \n",
    "    return risk_score, severity\n",
    "\n",
    "# Calculate risk for membership inference vulnerability\n",
    "potential_impact = 3  # High impact (GDPR/HIPAA violation)\n",
    "risk_score, severity = calculate_risk_score(attack_success_rate, potential_impact)\n",
    "\n",
    "print(f\"Risk Score: {risk_score}\")\n",
    "print(f\"Severity: {severity}\")\n",
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 4: GENERATE REPORT DATA\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nGenerating vulnerability report...\")\n",
    "\n",
    "report_data = {\n",
    "    \"vulnerability_id\": \"AI-VULN-001\",\n",
    "    \"title\": \"Membership Inference Attack - Training Data Leakage\",\n",
    "    \"discovered_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    \"severity\": severity,\n",
    "    \"risk_score\": risk_score,\n",
    "    \"affected_system\": \"MNIST Digit Classification Model\",\n",
    "    \"attack_type\": \"Membership Inference\",\n",
    "    \"attack_success_rate\": f\"{attack_success_rate:.2f}%\",\n",
    "    \"description\": (\n",
    "        \"The target ML model is vulnerable to membership inference attacks, \"\n",
    "        \"allowing attackers to determine whether specific data samples were \"\n",
    "        \"included in the training dataset.\"\n",
    "    ),\n",
    "    \"impact\": {\n",
    "        \"privacy\": \"Training data privacy compromised\",\n",
    "        \"compliance\": \"Potential GDPR/HIPAA violations\",\n",
    "        \"competitive\": \"Competitors can infer training data\"\n",
    "    },\n",
    "    \"recommendations\": [\n",
    "        \"Implement differential privacy during training\",\n",
    "        \"Add noise to model predictions\",\n",
    "        \"Limit prediction confidence scores\",\n",
    "        \"Regular adversarial testing\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 5: GENERATE EXECUTIVE SUMMARY\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nGenerating executive summary...\")\n",
    "\n",
    "def generate_executive_summary(report_data):\n",
    "    \"\"\"Generate executive summary section.\"\"\"\n",
    "    \n",
    "    summary = f\"\"\"\n",
    "# Executive Summary\n",
    "\n",
    "**Vulnerability ID**: {report_data['vulnerability_id']}\n",
    "**Title**: {report_data['title']}\n",
    "**Severity**: {report_data['severity']}\n",
    "**Risk Score**: {report_data['risk_score']:.1f}/10\n",
    "\n",
    "## Overview\n",
    "{report_data['description']}\n",
    "\n",
    "## Impact\n",
    "{len(report_data['impact'])} critical areas affected:\n",
    "\"\"\"\n",
    "    \n",
    "    # TODO: Add impact items\n",
    "    # HINT: Loop through report_data['impact'] and add to summary\n",
    "    for key, value in report_data['impact'].items():\n",
    "        summary += f\"- **{key.capitalize()}**: {value}\\n\"\n",
    "    \n",
    "    summary += f\"\\n## Attack Success Rate\\n{report_data['attack_success_rate']} (Random guess would be 50%)\\n\"\n",
    "    \n",
    "    return summary\n",
    "\n",
    "executive_summary = generate_executive_summary(report_data)\n",
    "print(executive_summary)\n",
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 6: GENERATE VISUALIZATIONS\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nGenerating report visualizations...\")\n",
    "\n",
    "def create_risk_visualization(attack_success_rate, risk_score, severity):\n",
    "    \"\"\"Create risk assessment visualization.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Attack success rate chart\n",
    "    axes[0].bar(['Random Guess', 'Attack Success'], [50, attack_success_rate], \n",
    "                color=['gray', 'red'])\n",
    "    axes[0].set_ylim([0, 100])\n",
    "    axes[0].set_ylabel('Success Rate (%)')\n",
    "    axes[0].set_title('Membership Inference Attack Success Rate')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add threshold line at 50%\n",
    "    axes[0].axhline(y=50, color='gray', linestyle='--', linewidth=2, label='Random Baseline')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Risk score visualization\n",
    "    severity_colors = {'Low': 'green', 'Medium': 'yellow', 'High': 'orange', 'Critical': 'red'}\n",
    "    bar = axes[1].bar([0], [risk_score], color=severity_colors.get(severity, 'gray'), width=0.3)\n",
    "    axes[1].set_xlim([-0.5, 0.5])\n",
    "    axes[1].set_ylim([0, 10])\n",
    "    axes[1].set_ylabel('Risk Score')\n",
    "    axes[1].set_title(f'Risk Assessment\\nSeverity: {severity}')\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add severity zones\n",
    "    axes[1].axhspan(0, 3, alpha=0.1, color='green', label='Low')\n",
    "    axes[1].axhspan(3, 6, alpha=0.1, color='yellow', label='Medium')\n",
    "    axes[1].axhspan(6, 9, alpha=0.1, color='orange', label='High')\n",
    "    axes[1].axhspan(9, 10, alpha=0.1, color='red', label='Critical')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('week-2/vulnerability_risk_assessment.png', dpi=150)\n",
    "    print(\"Saved: vulnerability_risk_assessment.png\")\n",
    "\n",
    "create_risk_visualization(attack_success_rate, risk_score, severity)\n",
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 7: GENERATE FULL REPORT\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nGenerating full vulnerability report...\")\n",
    "\n",
    "def generate_full_report(report_data, executive_summary):\n",
    "    \"\"\"Generate complete vulnerability report in Markdown format.\"\"\"\n",
    "    \n",
    "    report = f\"\"\"# AI Vulnerability Report\n",
    "\n",
    "{executive_summary}\n",
    "\n",
    "## Technical Details\n",
    "\n",
    "### Vulnerability Information\n",
    "- **Vulnerability ID**: {report_data['vulnerability_id']}\n",
    "- **Discovered Date**: {report_data['discovered_date']}\n",
    "- **Attack Type**: {report_data['attack_type']}\n",
    "- **Affected System**: {report_data['affected_system']}\n",
    "\n",
    "### Attack Methodology\n",
    "1. Extracted prediction features from target model\n",
    "2. Trained attack model on shadow models\n",
    "3. Achieved {report_data['attack_success_rate']} success rate\n",
    "4. Validated on test samples\n",
    "\n",
    "### Proof of Concept\n",
    "Attack successfully identified training data membership with {report_data['attack_success_rate']} accuracy,\n",
    "significantly above the 50% random baseline.\n",
    "\n",
    "## Remediation Recommendations\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    # TODO: Add recommendations\n",
    "    # HINT: Loop through report_data['recommendations'] and add numbered list\n",
    "    for i, rec in enumerate(report_data['recommendations'], 1):\n",
    "        report += f\"{i}. {rec}\\n\"\n",
    "    \n",
    "    report += \"\"\"\n",
    "## Compliance Impact\n",
    "\n",
    "- **GDPR**: Potential violation of data privacy regulations\n",
    "- **HIPAA**: Compromised patient data privacy\n",
    "- **SOC 2**: Control failure in data protection\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Implement differential privacy training\n",
    "2. Schedule adversarial testing quarterly\n",
    "3. Review data handling procedures\n",
    "4. Update model documentation\n",
    "\"\"\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "full_report = generate_full_report(report_data, executive_summary)\n",
    "\n",
    "# Save report\n",
    "report_path = Path('week-2') / f\"vulnerability_report_{report_data['vulnerability_id']}.md\"\n",
    "report_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(full_report)\n",
    "\n",
    "print(f\"Saved: {report_path}\")\n",
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# DOCUMENTATION\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Exercise 3 Complete!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nWhat you accomplished:\")\n",
    "print(\"1. \u2713 Calculated risk metrics for membership inference vulnerability\")\n",
    "print(\"2. \u2713 Generated executive summary for stakeholders\")\n",
    "print(\"3. \u2713 Created risk assessment visualizations\")\n",
    "print(\"4. \u2713 Generated full professional vulnerability report\")\n",
    "\n",
    "print(\"\\nRed Team Context:\")\n",
    "print(\"- Vulnerability reports are your primary deliverable\")\n",
    "print(\"- Executive summary must be clear to non-technical stakeholders\")\n",
    "print(\"- Risk assessment drives remediation priority\")\n",
    "print(\"- Professional documentation builds client trust\")\n",
    "\n",
    "print(\"\\nReport Components:\")\n",
    "print(\"- Executive summary for C-level stakeholders\")\n",
    "print(\"- Technical details for engineering teams\")\n",
    "print(\"- Risk assessment with visualizations\")\n",
    "print(\"- Remediation recommendations with priorities\")\n",
    "print(\"- Compliance impact analysis\")\n",
    "\n",
    "print(\"\\nThis is what you deliver to clients in real AI pentest engagements!\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}