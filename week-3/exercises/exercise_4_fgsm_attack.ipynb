{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Week 3 - Exercise 1: FGSM (Fast Gradient Sign Method) Attack\n",
    "\n",
    "Objective: Implement FGSM from scratch to generate adversarial samples\n",
    "\n",
    "Red Team Context: FGSM is the simplest evasion attack - fast to execute, easy to understand.\n",
    "Like SQL injection payloads, adversarial samples look normal but bypass security controls.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "This script is ~85% complete. Fill in the TODO sections marked with:\n",
    "  # TODO: Your implementation here\n",
    "  \n",
    "Each TODO includes hints. Read carefully before implementing.\n",
    "\n",
    "Expected Evasion Rate: >80% with \u03b5=0.3\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 1: SETUP AND IMPORTS\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\"*70)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"FGSM Attack Implementation\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\"*70)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 2: LOAD TRAINED MODEL FROM WEEK 1\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nLoading trained MNIST model from Week 1...\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# Define model architecture (same as Week 1)\n",
    "class MNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Load trained model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MNIST_CNN().to(device)\n",
    "\n",
    "model_path = Path(__file__).parent.parent.parent / \"models\" / \"mnist_cnn.pt\"\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(\"\u26a0 Error: Week 1 model not found!\")\n",
    "    print(\"   Please run Week 1, Exercise 1 first to train the model.\")\n",
    "    exit()\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "print(f\"\u2713 Model loaded successfully on {device}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 3: LOAD TEST DATA\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nLoading test data...\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Get a small sample for testing\n",
    "test_images, test_labels = next(iter(test_loader))\n",
    "test_images = test_images[:10].to(device)\n",
    "test_labels = test_labels[:10].to(device)\n",
    "\n",
    "print(f\"Loaded {len(test_images)} test samples\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 4: IMPLEMENT FGSM ATTACK\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nImplementing FGSM attack...\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "def fgsm_attack(model, images, labels, epsilon=0.3):\n",
    "    \"\"\"\n",
    "    Perform FGSM attack on model.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Compute loss\n",
    "    2. Get gradient of loss w.r.t. input\n",
    "    3. Take sign of gradient\n",
    "    4. Add epsilon * sign to original image\n",
    "    5. Clip to valid range [0, 1]\n",
    "    \n",
    "    Args:\n",
    "        model: Target model to attack\n",
    "        images: Input images to perturb\n",
    "        labels: True labels for images\n",
    "        epsilon: Perturbation strength (budget)\n",
    "    \n",
    "    Returns:\n",
    "        perturbed_images: Adversarial samples\n",
    "    \"\"\"\n",
    "    # Set requires_grad on inputs\n",
    "    # TODO: Enable gradient computation on images\n",
    "    # HINT: images.requires_grad_(True)\n",
    "    images.requires_grad_(True)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    \n",
    "    # Compute loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # TODO: Calculate loss\n",
    "    # HINT: loss = criterion(outputs, labels)\n",
    "    loss = None  # Replace with calculation\n",
    "    \n",
    "    # Backward pass to get gradients\n",
    "    model.zero_grad()\n",
    "    # TODO: Compute gradients\n",
    "    # HINT: loss.backward()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Get sign of gradients\n",
    "    # TODO: Extract gradient signs\n",
    "    # HINT: sign_data = images.grad.sign()\n",
    "    sign_data = None  # Replace with gradient sign extraction\n",
    "    \n",
    "    # Create adversarial samples\n",
    "    # TODO: Add perturbation to images\n",
    "    # HINT: perturbed_images = images + epsilon * sign_data\n",
    "    perturbed_images = None  # Replace with perturbation addition\n",
    "    \n",
    "    # Clip to [0, 1] range\n",
    "    # TODO: Clip values to valid range\n",
    "    # HINT: perturbed_images = torch.clamp(perturbed_images, 0, 1)\n",
    "    perturbed_images = None  # Replace with clamping\n",
    "    \n",
    "    return perturbed_images\n",
    "\n",
    "# Test FGSM attack\n",
    "print(\"Generating adversarial samples with \u03b5=0.3...\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "epsilon = 0.3\n",
    "\n",
    "# Apply FGSM attack\n",
    "perturbed_images = fgsm_attack(model, test_images, test_labels, epsilon)\n",
    "\n",
    "if perturbed_images is None:\n",
    "    print(\"\u26a0 TODO: Implement FGSM attack function\")\n",
    "    exit()\n",
    "\n",
    "print(\"\u2713 Adversarial samples generated\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 5: EVALUATE ATTACK SUCCESS\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nEvaluating attack success...\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "def evaluate_model(model, images, labels):\n",
    "    \"\"\"Evaluate model accuracy on given images and labels.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        accuracy = 100.0 * correct / len(labels)\n",
    "    return accuracy, predicted\n",
    "\n",
    "# Evaluate on clean images\n",
    "clean_accuracy, clean_predicted = evaluate_model(model, test_images, test_labels)\n",
    "print(f\"Clean accuracy: {clean_accuracy:.2f}%\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# Evaluate on adversarial images\n",
    "adversarial_accuracy, adversarial_predicted = evaluate_model(model, perturbed_images, test_labels)\n",
    "print(f\"Adversarial accuracy: {adversarial_accuracy:.2f}%\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# Calculate evasion rate\n",
    "evasion_rate = 100 - adversarial_accuracy\n",
    "print(f\"\\nAttack success rate: {evasion_rate:.2f}%\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "if evasion_rate > 80:\n",
    "    print(\"\u2713 SUCCESS: High evasion rate achieved!\")\n",
    "else:\n",
    "    print(\"\u26a0 Attack could be stronger. Check implementation.\")\n",
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 6: VISUALIZE RESULTS\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nVisualizing adversarial samples...\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "\n",
    "for i in range(5):\n",
    "    # Original image\n",
    "    axes[0, i].imshow(test_images[i].cpu().squeeze(), cmap='gray')\n",
    "    axes[0, i].set_title(f'Original\\nTrue: {test_labels[i].item()}\\nPred: {clean_predicted[i].item()}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Adversarial image\n",
    "    axes[1, i].imshow(perturbed_images[i].detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[1, i].set_title(f'Adversarial\\nTrue: {test_labels[i].item()}\\nPred: {adversarial_predicted[i].item()}')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Perturbation\n",
    "    perturbation = (perturbed_images[i] - test_images[i]).detach().cpu().squeeze()\n",
    "    axes[2, i].imshow(perturbation, cmap='RdBu_r', vmin=-epsilon, vmax=epsilon)\n",
    "    axes[2, i].set_title(f'Perturbation\\n(\u03b5={epsilon})')\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('week-3/fgsm_attack_results.png', dpi=150)\n",
    "print(\"Saved: fgsm_attack_results.png\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# STEP 7: EXPERIMENT WITH DIFFERENT EPSILON VALUES\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nTesting different epsilon values...\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "epsilons = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "accuracies = []\n",
    "evasion_rates = []\n",
    "\n",
    "for eps in epsilons:\n",
    "    perturbed = fgsm_attack(model, test_images, test_labels, eps)\n",
    "    acc, _ = evaluate_model(model, perturbed, test_labels)\n",
    "    evasion = 100 - acc\n",
    "    accuracies.append(acc)\n",
    "    evasion_rates.append(evasion)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epsilons, evasion_rates, 'o-', linewidth=2)\n",
    "plt.xlabel('Epsilon (\u03b5)', fontsize=12)\n",
    "plt.ylabel('Evasion Rate (%)', fontsize=12)\n",
    "plt.title('FGSM Attack: Evasion Rate vs Perturbation Budget', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=80, color='r', linestyle='--', label='Target (80%)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('week-3/fgsm_epsilon_analysis.png', dpi=150)\n",
    "print(\"Saved: fgsm_epsilon_analysis.png\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# DOCUMENTATION\n",
    "# ============================================================================\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*70)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Exercise 1 Complete!\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\"*70)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "print(\"\\nWhat you accomplished:\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"1. \u2713 Implemented FGSM attack from scratch\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"2. \u2713 Generated adversarial samples with \u03b5=0.3\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(f\"3. \u2713 Achieved {evasion_rate:.2f}% evasion rate\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"4. \u2713 Visualized adversarial examples and perturbations\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"5. \u2713 Analyzed effect of different epsilon values\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "print(\"\\nKey Insights:\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(f\"- Clean model accuracy: {clean_accuracy:.2f}%\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(f\"- Adversarial accuracy: {adversarial_accuracy:.2f}%\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(f\"- Attack reduced accuracy by {clean_accuracy - adversarial_accuracy:.2f}%\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(f\"- Best epsilon for attack: {epsilons[np.argmax(evasion_rates)]}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "print(\"\\nRed Team Context:\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"- FGSM is the simplest white-box evasion attack\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"- Fast to execute but less powerful than iterative attacks\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"- Demonstrates model vulnerability to adversarial samples\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"- Perturbations are imperceptible but highly effective\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "print(\"\\nNext Steps:\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"- Implement PGD for stronger attacks (Exercise 3)\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"- Compare FGSM vs PGD performance (Exercise 4)\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}